{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce82be45-0add-47a3-89b2-6ceaeac24512",
   "metadata": {},
   "source": [
    "# Downloading and Saving NOAA GOES-16 ABI Files\n",
    "\n",
    "This code retrieves and downloads NOAA GOES-16 ABI (Advanced Baseline Imager) data files for a specified time period. It accomplishes the following:\n",
    "\n",
    "1. **Initialize S3 Access**: Uses the `s3fs` library to interact with the AWS S3 bucket where NOAA GOES-16 data is stored.\n",
    "2. **File Retrieval**: Selects files based on the specified start and end year, day, and hour ranges.\n",
    "3. **Data Extraction**: Extracts meaningful information (e.g., product base name, date, and time) from file paths to create unique file names.\n",
    "4. **Download and Save**: Reads the selected files from the S3 bucket and saves them locally in a specified directory.\n",
    "\n",
    "The script is designed to handle potential errors, such as missing files, and skips over them without interrupting the process. The downloaded files are saved in NetCDF format for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15096cc9-fd95-4adf-a114-0b319c4dbf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import s3fs  # Library to interact with AWS S3 storage, used for reading and writing data directly from/to S3 buckets.\n",
    "import numpy as np  # Library for numerical operations, used for working with arrays and performing mathematical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f0ef5-feb3-40e8-b760-e90226f15ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect and save in a list the files available within the specified period of interest\n",
    "def get_files(s_year, e_year, s_day, e_day, s_hour, e_our):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    s_year (int): Start year of the period of interest.\n",
    "    e_year (int): End year of the period of interest.\n",
    "    s_day (int): Start day of the year (Julian day).\n",
    "    e_day (int): End day of the year (Julian day).\n",
    "    s_hour (int): Start hour (UTC).\n",
    "    e_our (int): End hour (UTC).\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of file paths for the specified period.\n",
    "    \"\"\"\n",
    "    print('Getting files')  # Log progress\n",
    "    aux = []  # Initialize an empty list to store file paths\n",
    "    \n",
    "    # Loop through each year in the specified range\n",
    "    for y in range(s_year, e_year + 1):\n",
    "        # Loop through each day (Julian day) within the specified range\n",
    "        for d in range(s_day, e_day):\n",
    "            # Loop through each hour within the specified range\n",
    "            for j in range(s_hour, e_our):\n",
    "                try:\n",
    "                    # Construct the path to the desired files in the NOAA GOES-16 dataset on S3\n",
    "                    # Example path structure: 'noaa-goes16/ABI-L2-FDCF/<year>/<Julian day>/<hour>/'\n",
    "                    FD = fs.ls('noaa-goes16/ABI-L2-FDCF/' + str(y) + '/' + str(d).zfill(3) + '/' + str(j).zfill(2) + '/')\n",
    "                    \n",
    "                    # Append the retrieved file paths to the list\n",
    "                    aux = np.append(aux, FD)\n",
    "                except FileNotFoundError as e:\n",
    "                    # Log a warning and skip if the file is not found\n",
    "                    print(f\"FileNotFoundError for path 'noaa-goes16/ABI-L2-FDCF/{y}/{str(d).zfill(3)}/{str(j).zfill(2)}/': {e}. Skipping.\")\n",
    "                    continue  # Skip to the next file in the loop\n",
    "    \n",
    "    return aux  # Return the list of file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7810007-c971-4d7b-b7cb-a99ea68c939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an ABI netCDF4 data file\n",
    "\n",
    "# Step 1: Initialize the S3 file system\n",
    "fs = s3fs.S3FileSystem(anon=True, use_listings_cache=True)\n",
    "# The `anon=True` parameter indicates anonymous access to the AWS S3 bucket (no credentials required).\n",
    "# `use_listings_cache=True` improves performance by caching directory listings locally.\n",
    "\n",
    "# Step 2: Define the period of interest for retrieving files\n",
    "start_year, end_year = 2020, 2020  # Start and end year\n",
    "start_day, end_day = 210, 211  # Start and end Julian days (day of year)\n",
    "start_hour, end_our = 19, 20  # Start and end UTC hours (24-hour format)\n",
    "\n",
    "# Step 3: Use the `get_files` function to retrieve file paths from the specified period\n",
    "data_list = get_files(start_year, end_year, start_day, end_day, start_hour, end_our)\n",
    "\n",
    "# The resulting `data_list` will contain the paths to the files from the NOAA GOES-16 ABI dataset\n",
    "# that match the specified time range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5810dd66-4184-495b-819e-cd7e87a5569b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output directory for the data\n",
    "datadir = '/home/jovyan/...'  # Replace this with the desired directory path where the data will be saved.\n",
    "# Example: This path is specific to the current environment (e.g., a JupyterHub instance or local machine).\n",
    "# Update it based on your system's directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f0c079-1fcf-42e2-a977-2afc80bb74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the files selected previously\n",
    "for i in range(0, len(data_list)):\n",
    "    # Extract the base product name from the file path\n",
    "    # Example: 'OR_ABI-L2-FDCF-M6_G16_s20202101840180_e20202101845163_c20202101845226.nc'\n",
    "    prodbase = data_list[i].split('/')[5][:23]\n",
    "    \n",
    "    # Extract the date-time information from the file name\n",
    "    starttime = data_list[i].split('/')[5].split('_')[3]  # Example: 's20202101840180'\n",
    "    year, julian, hhmm = starttime[1:5], starttime[5:8], starttime[8:12]\n",
    "    # 'year' = '2020', 'julian' = '210' (day of year), 'hhmm' = '1840' (UTC time)\n",
    "    \n",
    "    # Format the date-time information for readability\n",
    "    date_info = year + '-' + julian + '-' + hhmm  # Example: '2020-210-1840'\n",
    "    \n",
    "    # Create a short file title using the product base and date-time information\n",
    "    fileshtitle = prodbase + '-' + date_info  # Example: 'OR_ABI-L2-FDCF-M6_G16_s2020-210-1840'\n",
    "    \n",
    "    # Open the remote file from S3 and save it locally in the defined directory\n",
    "    with fs.open(data_list[i], 'rb') as f:\n",
    "        # Write the file content to the local directory\n",
    "        with open(datadir + fileshtitle + '.nc', 'wb') as local_f:\n",
    "            local_f.write(f.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
