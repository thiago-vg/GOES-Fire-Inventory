{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing FRP and Temperature Data for ROI\n",
    "\n",
    "This code processes FRP and Temperature data from NetCDF files for a specified region of interest (ROI), calculates emission estimates, and saves the results in CSV files.\n",
    "\n",
    "1. Get Files Function  \n",
    "The `get_files` function retrieves relevant satellite files within a specified year, day, and hour range. It handles missing files gracefully using a `try-except` block.\n",
    "\n",
    "2. Get Indexes and Matrix Function  \n",
    "    `get_indexes_v3` creates a 0.5°x0.5° grid within the ROI and calculates the corresponding FEER coefficient for each grid cell, generating a matrix and a mask for valid data points.\n",
    "\n",
    "4. Processes FRP and Temperature function  \n",
    "   Processes FRP and Temperature data for the entire ROI and saves the results to CSV files.  \n",
    "   **Input**: List of files and valid indices  \n",
    "   **Output**: CSV files with valid FRP and Temperature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# os: Provides functions to interact with the operating system, such as file and directory operations\n",
    "import os\n",
    "# BytesIO: Enables reading and writing of binary data in memory as if it were a file\n",
    "from io import BytesIO\n",
    "# s3fs: A Pythonic interface to Amazon S3, allowing for easy file operations on S3 buckets\n",
    "import s3fs\n",
    "# xarray: A powerful library for working with multi-dimensional arrays, particularly for geospatial and time-series data\n",
    "import xarray as xr\n",
    "# numpy: Provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions\n",
    "import numpy as np\n",
    "# glob: Used for finding all pathnames matching a specified pattern, useful for file pattern matching in directories\n",
    "import glob\n",
    "# pyproj: Provides tools for working with projections and coordinate transformations, such as converting between latitude/longitude and projected coordinates\n",
    "from pyproj import Proj\n",
    "# pandas: A data analysis library that provides data structures like DataFrame for handling structured data, useful for working with time-series and tabular data\n",
    "import pandas as pd\n",
    "# warnings: Used to issue warnings to the user, often to alert about potential issues or deprecated features\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FV8vxe-9q2z6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-8jpjB-QtmC3"
   },
   "outputs": [],
   "source": [
    "# Define input and output folders and file\n",
    "datadir = '/home/jovyan/Article_review/Data/' #This directory will receive the csv file with processed data\n",
    "\n",
    "\n",
    "#Define output directory, the year for process the data and the file name\n",
    "#Is recommended for posterior plots to run this algorithm one year at a time\n",
    "outdir  = datadir\n",
    "Year =2022\n",
    "outfile = outdir+'array_T_data_'+str(Year)+'_150_350.csv'\n",
    "outfile2 = outdir+'array_P_data_'+str(Year)+'_150_350.csv'\n",
    "#Define the file header\n",
    "aux1 ='array_temp\\n'\n",
    "aux2 ='array_frp\\n'\n",
    "header = aux1\n",
    "header2 = aux2\n",
    "\n",
    "outstring=''\n",
    "outfn = open(outfile, 'w')\n",
    "outfn.writelines(header)\n",
    "outfn2 = open(outfile2, 'w')\n",
    "outfn2.writelines(header2)\n",
    "#Close the files\n",
    "outfn.close()\n",
    "outfn2.close()\n",
    "\n",
    "# Initialize S3 file system\n",
    "fs = s3fs.S3FileSystem(anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize geometric variables\n",
    "\n",
    "# This function extracts the geometric values (latitude and longitude) from one file,\n",
    "# which contains satellite coordinates, and calculates the corresponding matrix of latitudes and longitudes.\n",
    "# These values will be used for geospatial referencing in the satellite data.\n",
    "\n",
    "def get_lat_lon(file_system):\n",
    "    # List of 6 files from the 'noaa-goes16' directory for the specified date (2022, day 200) and time (15:00 to 15:50 UTC)\n",
    "    # The directory structure includes data at 10-minute intervals\n",
    "    files = file_system.ls('noaa-goes16/ABI-L2-FDCF/2022/'+str(200).zfill(3)+'/'+str(15).zfill(2)+'/')\n",
    "\n",
    "    # Open the first file in the list to extract the geospatial information\n",
    "    # Here, we use 'h5netcdf' as the engine to read the data from the file\n",
    "    with fs.open(files[0], 'rb') as f:\n",
    "        ds0 = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')\n",
    "\n",
    "    # Extract satellite geometric parameters from the file\n",
    "    # These parameters define the satellite's position and the projection system used\n",
    "    sat_h = ds0.goes_imager_projection.perspective_point_height  # Satellite height\n",
    "    sat_lon = ds0.goes_imager_projection.longitude_of_projection_origin  # Longitude of the satellite's projection origin\n",
    "    sat_sweep = ds0.goes_imager_projection.sweep_angle_axis  # Sweep angle axis of the satellite\n",
    "\n",
    "    # Create a geostationary projection object using pyproj\n",
    "    # This projection is used to convert the satellite's (x, y) coordinates into geographic (latitude, longitude) coordinates\n",
    "    p = Proj(proj='geos', h=sat_h, lon_0=sat_lon, sweep=sat_sweep)\n",
    "\n",
    "    # Multiply the x and y coordinates by the satellite height to scale them properly for the projection\n",
    "    X = np.array(ds0.x) * sat_h\n",
    "    Y = np.array(ds0.y) * sat_h\n",
    "\n",
    "    # Create mesh grids for the x and y coordinates\n",
    "    XX, YY = np.meshgrid(X, Y)\n",
    "\n",
    "    # Convert the satellite projection coordinates (XX, YY) into latitude and longitude\n",
    "    rlon, rlat = p(XX, YY, inverse=True)\n",
    "\n",
    "    # Return the calculated latitude and longitude matrices\n",
    "    return rlat, rlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to collect and save file names in a list for the given period of interest with error handling\n",
    "# This function iterates over the specified year, day, and hour ranges and collects the corresponding file names\n",
    "# from the NOAA GOES-16 directory structure, with added error handling for missing files.\n",
    "\n",
    "def get_files(s_year, e_year, s_day, e_day, s_hour, e_hour):\n",
    "    print('Getting file names')\n",
    "    aux = []  # List to store the file names\n",
    "    # Loop over the years in the specified range\n",
    "    for y in range(s_year, e_year + 1):\n",
    "        # Loop over the days in the specified range\n",
    "        for d in range(s_day, e_day):\n",
    "            # The variable 'd' determines the days of the product (e.g., day 228 corresponds to 15:00, 15:10, etc.)\n",
    "            for j in range(s_hour, e_hour):\n",
    "                try:\n",
    "                    # List the files for a specific year, day, and hour directory\n",
    "                    # These directories contain 6 files for each 10-minute interval (e.g., 15:00, 15:10, ..., 15:50 UTC)\n",
    "                    FD = fs.ls('noaa-goes16/ABI-L2-FDCF/' + str(y) + '/' + str(d).zfill(3) + '/' + str(j).zfill(2) + '/')\n",
    "                    aux = np.append(aux, FD)  # Append the found files to the list\n",
    "                except FileNotFoundError as e:\n",
    "                    # In case a file is not found, print an error message and skip to the next file\n",
    "                    print(f\"FileNotFoundError file {'noaa-goes16/ABI-L2-FDCF/'+str(y)+'/'+str(d).zfill(3)+'/'+str(j).zfill(2)+'/'}: {e}. Skipping this file.\")\n",
    "                    continue  # Skip to the next file in the list\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wB9cMZbyhDM0"
   },
   "outputs": [],
   "source": [
    "# Function to create a 0.5° x 0.5° grid and return the corresponding indices for a given region of interest (ROI)\n",
    "def get_indexes_v2(min_lon, max_lon, min_lat, max_lat, rlat, rlon):\n",
    "    # Calculate the center points of each grid element (0.5°x0.5°) within the ROI\n",
    "    centers_lon = np.linspace(minlon + 0.25, maxlon - 0.25, num=int(maxlon - minlon) * 2)  # Longitude centers\n",
    "    centers_lat = np.linspace(minlat + 0.25, maxlat - 0.25, num=int(maxlat - minlat) * 2)  # Latitude centers\n",
    "\n",
    "    # Create a matrix of (latitude, longitude) pairs for each grid center\n",
    "    for i in range(0, len(centers_lat)):\n",
    "        # Repeat latitude values for each corresponding longitude value\n",
    "        if i == 0:\n",
    "            aux = np.repeat(centers_lat[i], len(centers_lon))\n",
    "            lat_lon_feer = np.column_stack((aux, centers_lon))\n",
    "        else:\n",
    "            aux = np.repeat(centers_lat[i], len(centers_lon))\n",
    "            aux2 = np.column_stack((aux, centers_lon))\n",
    "            lat_lon_feer = np.vstack((lat_lon_feer, aux2))\n",
    "\n",
    "    # Save the (latitude, longitude) grid centers in a matrix\n",
    "    matrix = lat_lon_feer\n",
    "\n",
    "    # Create a mask to select valid points within the ROI based on latitude and longitude\n",
    "    Idx = np.where((rlat >= min_lat) & (rlat <= max_lat) & (rlon >= min_lon) & (rlon <= max_lon))\n",
    "    index_list = []\n",
    "    index_list.insert(0, Idx)\n",
    "\n",
    "    # Generate indices for each 0.5°x0.5° grid element and add them to the list\n",
    "    for k in range(0, len(matrix)):\n",
    "        aux1 = np.where((rlat >= matrix[k, 0] - 0.25) & (rlat <= matrix[k, 0] + 0.25) &\n",
    "                        (rlon >= matrix[k, 1] - 0.25) & (rlon <= matrix[k, 1] + 0.25))\n",
    "        index_list.insert(k + 1, aux1)\n",
    "\n",
    "    return index_list, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nQ4Wr1OdxYOx"
   },
   "outputs": [],
   "source": [
    "# Main function to process files, collect FRP (Fire Radiative Power) and Temperature data\n",
    "# It calculates emission estimates using the FEER coefficients and FRP, then saves the spatial\n",
    "# and temporal information, as well as the results, in CSV files for further analysis\n",
    "def process_data_v6(files, indexes):\n",
    "\n",
    "    all_array_T = []  # List to store temperature values\n",
    "    all_array_P = []  # List to store FRP (Power) values\n",
    "\n",
    "    # Change the directory to save the CSV files\n",
    "    os.chdir(outdir)\n",
    "    outfn = open(outfile, 'w')   # CSV file for Temperature data\n",
    "    outfn2 = open(outfile2, 'w') # CSV file for FRP (Power) data\n",
    "\n",
    "    # Loop through the list of files to process each one\n",
    "    for i in range(0, len(files)):\n",
    "        with fs.open(files[i], 'rb') as f:\n",
    "            # Open the file and load the data into the 'ds' variable (dataset)\n",
    "            ds = xr.open_dataset(BytesIO(f.read()), engine='h5netcdf')\n",
    "            try:\n",
    "                # Extract the datetime information from the file name\n",
    "                prodbase = files[i].split('/')[5][:23]\n",
    "                starttime = files[i].split(prodbase)[1].split('_')[0]\n",
    "                year, julian, hhmm = starttime[:4], starttime[4:7], starttime[7:11]\n",
    "                print(f'Processing year: {year}, day: {julian}, hour: {hhmm}', end='\\r')\n",
    "\n",
    "                #####################################################################\n",
    "                # Extract FRP (Fire Radiative Power) and Temperature matrix data\n",
    "                P = np.array(ds.Power)  # FRP (Power) matrix\n",
    "                T = np.array(ds.Temp)   # Temperature matrix\n",
    "\n",
    "                # Use the index matrix to extract data for the region of interest (ROI)\n",
    "                P_box_amazon = P[indexes]\n",
    "                T_box_amazon = T[indexes]\n",
    "\n",
    "                # Convert valid data points (non-NaN) from matrices to arrays to reduce processing demand\n",
    "                array_P_box_amazon = P_box_amazon[~np.isnan(P_box_amazon)]\n",
    "                array_T_box_amazon = T_box_amazon[~np.isnan(T_box_amazon)]\n",
    "\n",
    "                # Write the valid Temperature and FRP values to separate CSV files\n",
    "                # These files will be used to analyze the distribution of FRP and Temperature over the ROI\n",
    "                for value in array_T_box_amazon:\n",
    "                    outstring = f'{value}\\n'\n",
    "                    outfn.writelines(outstring)\n",
    "                for value in array_P_box_amazon:\n",
    "                    outstring = f'{value}\\n'\n",
    "                    outfn2.writelines(outstring)\n",
    "\n",
    "            # Handle any exceptions that occur during file processing\n",
    "            except OSError as error:\n",
    "                print(error)\n",
    "\n",
    "    # Close the output CSV files after processing all the data\n",
    "    outfn.close()\n",
    "    outfn2.close()\n",
    "\n",
    "    # Print completion message\n",
    "    return print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6sZuoCvuCkr",
    "outputId": "e07e7cb0-a890-444a-9a05-f26197db1726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling statistics\n",
      "Got indexes and matrix\n",
      "Getting file names\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/11/: noaa-goes16/ABI-L2-FDCF/2022/256/11. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/12/: noaa-goes16/ABI-L2-FDCF/2022/256/12. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/13/: noaa-goes16/ABI-L2-FDCF/2022/256/13. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/14/: noaa-goes16/ABI-L2-FDCF/2022/256/14. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/15/: noaa-goes16/ABI-L2-FDCF/2022/256/15. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/16/: noaa-goes16/ABI-L2-FDCF/2022/256/16. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/17/: noaa-goes16/ABI-L2-FDCF/2022/256/17. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/18/: noaa-goes16/ABI-L2-FDCF/2022/256/18. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/19/: noaa-goes16/ABI-L2-FDCF/2022/256/19. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/256/20/: noaa-goes16/ABI-L2-FDCF/2022/256/20. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/311/20/: noaa-goes16/ABI-L2-FDCF/2022/311/20. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/311/21/: noaa-goes16/ABI-L2-FDCF/2022/311/21. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/311/22/: noaa-goes16/ABI-L2-FDCF/2022/311/22. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/311/23/: noaa-goes16/ABI-L2-FDCF/2022/311/23. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/312/00/: noaa-goes16/ABI-L2-FDCF/2022/312/00. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/320/19/: noaa-goes16/ABI-L2-FDCF/2022/320/19. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/320/20/: noaa-goes16/ABI-L2-FDCF/2022/320/20. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/321/18/: noaa-goes16/ABI-L2-FDCF/2022/321/18. Skipping this file.\n",
      "FileNotFoundError file noaa-goes16/ABI-L2-FDCF/2022/321/20/: noaa-goes16/ABI-L2-FDCF/2022/321/20. Skipping this file.\n",
      "Data listed\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# Define a ROI in degrees\n",
    "minlon,maxlon,minlat,maxlat=-57,-54,-9,-6 #Amazon small box\n",
    "#minlon,maxlon,minlat,maxlat=-56,-54,-9,-7 #Amazon small box - corrected\n",
    "#minlon,maxlon,minlat,maxlat=-72,-48,-11,-3 #Amazon ROI\n",
    "# minlon,maxlon,minlat,maxlat=-57.5,-56.5,-17.5,-16.5 # cerrado big box\n",
    "\n",
    "#Starting message\n",
    "print('Compiling statistics')\n",
    "\n",
    "rlat,rlon = get_lat_lon(fs)\n",
    "\n",
    "Indexes,M = get_indexes_v2(minlon,maxlon,minlat,maxlat,rlat,rlon)\n",
    "print('Got indexes and matrix')\n",
    "\n",
    "start_year,end_year,start_day,end_day,start_hour,end_our = Year,Year,150,350,0,24\n",
    "data_list = get_files(start_year,end_year,start_day,end_day,start_hour,end_our)\n",
    "print('Data listed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting process data\n",
      "Doneessing year: 2022, day: 349, hour: 2350\n"
     ]
    }
   ],
   "source": [
    "print('Starting process data')\n",
    "process_data_v6(data_list,Indexes[0])#For this version of the code we need just the index just for the whole ROI, the 0.5x0.5 grid it's not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
